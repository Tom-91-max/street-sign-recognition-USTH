{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06b4c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# C·∫•u h√¨nh plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c451e8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TH√îNG TIN DATASET G·ªêC\n",
      "============================================================\n",
      "T·ªïng s·ªë annotations: 11,000\n",
      "T·ªïng s·ªë ·∫£nh unique: 4,500\n",
      "T·ªïng s·ªë classes: 7\n",
      "\n",
      "üìã Columns trong dataset:\n",
      "['area', 'iscrowd', 'image_id', 'bbox', 'category_id', 'box_id', 'file_name', 'height', 'width', 'street_id', 'supercategory']\n",
      "\n",
      "üîç Sample data (5 d√≤ng ƒë·∫ßu):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>image_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>box_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>street_id</th>\n",
       "      <th>supercategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>342</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[880, 333, 19, 18]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.png</td>\n",
       "      <td>626</td>\n",
       "      <td>1622</td>\n",
       "      <td>3</td>\n",
       "      <td>C·∫•m d·ª´ng v√† ƒë·ªó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[768, 480, 9, 7]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5.png</td>\n",
       "      <td>626</td>\n",
       "      <td>1622</td>\n",
       "      <td>4</td>\n",
       "      <td>C·∫•m d·ª´ng v√† ƒë·ªó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>[733, 352, 7, 8]</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16.png</td>\n",
       "      <td>626</td>\n",
       "      <td>1622</td>\n",
       "      <td>3</td>\n",
       "      <td>C·∫•m d·ª´ng v√† ƒë·ªó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5400</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>[1024, 160, 75, 72]</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>17.png</td>\n",
       "      <td>626</td>\n",
       "      <td>1622</td>\n",
       "      <td>8</td>\n",
       "      <td>C·∫•m d·ª´ng v√† ƒë·ªó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1927</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>[1138, 295, 47, 41]</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>18.png</td>\n",
       "      <td>626</td>\n",
       "      <td>1622</td>\n",
       "      <td>3</td>\n",
       "      <td>C·∫•m d·ª´ng v√† ƒë·ªó</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   area  iscrowd  image_id                 bbox  category_id  box_id  \\\n",
       "0   342        0         3   [880, 333, 19, 18]            2       0   \n",
       "1    63        0         5     [768, 480, 9, 7]            2       2   \n",
       "2    56        0        16     [733, 352, 7, 8]            2       4   \n",
       "3  5400        0        17  [1024, 160, 75, 72]            2       5   \n",
       "4  1927        0        18  [1138, 295, 47, 41]            2       6   \n",
       "\n",
       "  file_name  height  width  street_id   supercategory  \n",
       "0     3.png     626   1622          3  C·∫•m d·ª´ng v√† ƒë·ªó  \n",
       "1     5.png     626   1622          4  C·∫•m d·ª´ng v√† ƒë·ªó  \n",
       "2    16.png     626   1622          3  C·∫•m d·ª´ng v√† ƒë·ªó  \n",
       "3    17.png     626   1622          8  C·∫•m d·ª´ng v√† ƒë·ªó  \n",
       "4    18.png     626   1622          3  C·∫•m d·ª´ng v√† ƒë·ªó  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/images/annotation.csv')\n",
    "\n",
    "print(\"üìä TH√îNG TIN DATASET G·ªêC\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"T·ªïng s·ªë annotations: {len(df):,}\")\n",
    "print(f\"T·ªïng s·ªë ·∫£nh unique: {df['file_name'].nunique():,}\")\n",
    "print(f\"T·ªïng s·ªë classes: {df['category_id'].nunique()}\")\n",
    "print(\"\\nüìã Columns trong dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nüîç Sample data (5 d√≤ng ƒë·∫ßu):\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c183a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng classes: 7\n",
      "Classes: {0: 'warning', 1: 'no parking/waiting', 2: 'other prohibition signs', 3: 'no entry', 4: 'mandatory', 5: 'max speed', 6: 'no turning'}\n"
     ]
    }
   ],
   "source": [
    "with open('../configs/zalo.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "class_names = config['names']\n",
    "print(f\"S·ªë l∆∞·ª£ng classes: {len(class_names)}\")\n",
    "print(f\"Classes: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbb3a952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä TH·ªêNG K√ä DATASET\n",
      "==================================================\n",
      "Train images: 4500\n",
      "Val images: 0\n",
      "Test images: 586\n",
      "Total: 5086\n"
     ]
    }
   ],
   "source": [
    "train_images = glob.glob('../data/images/train/*.jpg') + glob.glob('../data/images/train/*.png')\n",
    "val_images = glob.glob('../data/images/val/*.jpg') + glob.glob('../data/images/val/*.png')\n",
    "test_images = glob.glob('../data/images/test/*.jpg') + glob.glob('../data/images/test/*.png')\n",
    "\n",
    "print(f\"üìä TH·ªêNG K√ä DATASET\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Train images: {len(train_images)}\")\n",
    "# ƒëang thi·∫øu val images trong data\n",
    "print(f\"Val images: {len(val_images)}\")\n",
    "print(f\"Test images: {len(test_images)}\")\n",
    "print(f\"Total: {len(train_images) + len(val_images) + len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5625a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà TH·ªêNG K√ä THEO CLASS\n",
      "============================================================\n",
      "                 Count  Mean_Area  Std_Area  Min_Area  Max_Area\n",
      "supercategory                                                  \n",
      "C·∫•m c√≤n l·∫°i       1787    1069.71   2547.62         9     45024\n",
      "C·∫•m d·ª´ng v√† ƒë·ªó    2221    1368.00   3135.65         9     54526\n",
      "C·∫•m ng∆∞·ª£c chi·ªÅu   1416     538.40   1428.91         4     15006\n",
      "C·∫•m r·∫Ω             556    1705.58   3451.42        24     24402\n",
      "Gi·ªõi h·∫°n t·ªëc ƒë·ªô    949     828.65   1552.66         9     22363\n",
      "Hi·ªáu l·ªánh         1022     696.79   1928.02         6     27300\n",
      "Nguy hi·ªÉm         3049    1164.60   2960.21         9     47736\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìà TH·ªêNG K√ä THEO CLASS\")\n",
    "print(\"=\" * 60)\n",
    "class_stats = df.groupby('supercategory').agg({\n",
    "    'box_id': 'count',\n",
    "    'area': ['mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "class_stats.columns = ['Count', 'Mean_Area', 'Std_Area', 'Min_Area', 'Max_Area']\n",
    "print(class_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19480ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìê TH·ªêNG K√ä K√çCH TH∆Ø·ªöC ·∫¢NH\n",
      "============================================================\n",
      "Unique image sizes: [[1622, 626]]\n",
      "Chi·ªÅu r·ªông: [1622]\n",
      "Chi·ªÅu cao: [626]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüìê TH·ªêNG K√ä K√çCH TH∆Ø·ªöC ·∫¢NH\")\n",
    "print(\"=\" * 60)\n",
    "img_sizes = df[['file_name', 'width', 'height']].drop_duplicates()\n",
    "print(f\"Unique image sizes: {img_sizes[['width', 'height']].drop_duplicates().values.tolist()}\")\n",
    "print(f\"Chi·ªÅu r·ªông: {img_sizes['width'].unique()}\")\n",
    "print(f\"Chi·ªÅu cao: {img_sizes['height'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e42657e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Total unique images: 4500\n",
      "\n",
      "üìä DATASET SPLIT\n",
      "============================================================\n",
      "üü¶ Train: 3,150 images (70.0%)\n",
      "üü® Val:   904 images (20.1%)\n",
      "üü• Test:  446 images (9.9%)\n"
     ]
    }
   ],
   "source": [
    "# L·∫•y danh s√°ch ·∫£nh unique\n",
    "image_files = df['file_name'].unique()\n",
    "print(f\"üìÇ Total unique images: {len(image_files)}\")\n",
    "\n",
    "# Split: 70% train, 20% val, 10% test\n",
    "train_imgs, temp_imgs = train_test_split(\n",
    "    image_files, test_size=0.3, random_state=42, shuffle=True\n",
    ")\n",
    "val_imgs, test_imgs = train_test_split(\n",
    "    temp_imgs, test_size=0.33, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä DATASET SPLIT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üü¶ Train: {len(train_imgs):,} images ({len(train_imgs)/len(image_files)*100:.1f}%)\")\n",
    "print(f\"üü® Val:   {len(val_imgs):,} images ({len(val_imgs)/len(image_files)*100:.1f}%)\")\n",
    "print(f\"üü• Test:  {len(test_imgs):,} images ({len(test_imgs)/len(image_files)*100:.1f}%)\")\n",
    "\n",
    "# T·∫°o dictionary ƒë·ªÉ mapping\n",
    "split_dict = {}\n",
    "for img in train_imgs:\n",
    "    split_dict[img] = 'train'\n",
    "for img in val_imgs:\n",
    "    split_dict[img] = 'val'\n",
    "for img in test_imgs:\n",
    "    split_dict[img] = 'test'\n",
    "\n",
    "df['split'] = df['file_name'].map(split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4126db56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting annotations to YOLO format...\n",
      "============================================================\n",
      "‚úÖ Conversion completed!\n",
      "   Train: 3150 label files created\n",
      "   Val: 904 label files created\n",
      "   Test: 446 label files created\n",
      "\n",
      "üìù Sample label file (10002.txt):\n",
      "6 0.435265 0.555911 0.008631 0.022364\n",
      "6 0.435573 0.555911 0.006782 0.019169\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def convert_bbox_to_yolo(bbox_str, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert COCO bbox [x_min, y_min, width, height] \n",
    "    to YOLO format [x_center, y_center, width, height] (normalized)\n",
    "    \"\"\"\n",
    "    bbox = json.loads(bbox_str)\n",
    "    x_min, y_min, bbox_width, bbox_height = bbox\n",
    "    \n",
    "    # Calculate center\n",
    "    x_center = (x_min + bbox_width / 2) / img_width\n",
    "    y_center = (y_min + bbox_height / 2) / img_height\n",
    "    \n",
    "    # Normalize width and height\n",
    "    norm_width = bbox_width / img_width\n",
    "    norm_height = bbox_height / img_height\n",
    "    \n",
    "    return x_center, y_center, norm_width, norm_height\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c output\n",
    "for split in ['train', 'val', 'test']:\n",
    "    Path(f'../data/images/{split}').mkdir(parents=True, exist_ok=True)\n",
    "    Path(f'../data/labels/{split}').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üîÑ Converting annotations to YOLO format...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "conversion_stats = {'train': 0, 'val': 0, 'test': 0}\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_df = df[df['split'] == split]\n",
    "    \n",
    "    for image_file, group in split_df.groupby('file_name'):\n",
    "        img_width = group.iloc[0]['width']\n",
    "        img_height = group.iloc[0]['height']\n",
    "        \n",
    "        # T·∫°o file .txt label\n",
    "        label_file = Path(f'../data/labels/{split}') / f\"{Path(image_file).stem}.txt\"\n",
    "        \n",
    "        with open(label_file, 'w') as f:\n",
    "            for _, row in group.iterrows():\n",
    "                # S·ª≠ d·ª•ng category_id g·ªëc t·ª´ dataset\n",
    "                class_id = row['category_id']\n",
    "                x_c, y_c, w, h = convert_bbox_to_yolo(\n",
    "                    row['bbox'], img_width, img_height\n",
    "                )\n",
    "                f.write(f\"{class_id} {x_c:.6f} {y_c:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "        \n",
    "        conversion_stats[split] += 1\n",
    "\n",
    "print(\"‚úÖ Conversion completed!\")\n",
    "for split, count in conversion_stats.items():\n",
    "    print(f\"   {split.capitalize()}: {count} label files created\")\n",
    "\n",
    "# Verify m·ªôt file m·∫´u\n",
    "sample_label = Path('../data/labels/train').glob('*.txt').__next__()\n",
    "print(f\"\\nüìù Sample label file ({sample_label.name}):\")\n",
    "print(sample_label.read_text()[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b41dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config file created: configs/zalo.yaml\n",
      "\n",
      "üìÑ Config content:\n",
      "names:\n",
      "  1: C·∫•m ng∆∞·ª£c chi·ªÅu\n",
      "  2: C·∫•m d·ª´ng v√† ƒë·ªó\n",
      "  3: C·∫•m r·∫Ω\n",
      "  4: Gi·ªõi h·∫°n t·ªëc ƒë·ªô\n",
      "  5: C·∫•m c√≤n l·∫°i\n",
      "  6: Nguy hi·ªÉm\n",
      "  7: Hi·ªáu l·ªánh\n",
      "nc: 7\n",
      "path: ./data\n",
      "test: images/test\n",
      "train: images/train\n",
      "val: images/val\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'path': './data',\n",
    "    'train': 'images/train',\n",
    "    'val': 'images/val',\n",
    "    'test': 'images/test',\n",
    "    'nc': num_classes,\n",
    "    'names': class_names  # YOLO format: {0: 'warning', 1: 'no parking/waiting', ...}\n",
    "}\n",
    "\n",
    "config_path = Path('../configs/zalo.yaml')\n",
    "config_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(\"‚úÖ Config file created: configs/zalo.yaml\")\n",
    "print(\"\\nüìÑ Config content:\")\n",
    "print(yaml.dump(config, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "343c8d14",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'class_name_en'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m split_class_stats = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msplit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclass_name_en\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.size().unstack(fill_value=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Reorder columns by YOLO class ID\u001b[39;00m\n\u001b[32m      4\u001b[39m ordered_cols = [class_names[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(class_names.keys())]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Welcome\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Welcome\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Welcome\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'class_name_en'"
     ]
    }
   ],
   "source": [
    "split_class_stats = df.groupby(['split', 'class_name_en']).size().unstack(fill_value=0)\n",
    "\n",
    "# Reorder columns by YOLO class ID\n",
    "ordered_cols = [class_names[i] for i in sorted(class_names.keys())]\n",
    "split_class_stats = split_class_stats[ordered_cols]\n",
    "\n",
    "print(\"üìä CLASS DISTRIBUTION BY SPLIT\")\n",
    "print(\"=\" * 80)\n",
    "print(split_class_stats)\n",
    "print(\"\\nüìà Total per split:\")\n",
    "print(split_class_stats.sum(axis=1))\n",
    "print(\"\\nüìà Total per class:\")\n",
    "print(split_class_stats.sum(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
